{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import copy\n",
    "\n",
    "import torch\n",
    "from pyro.distributions import constraints\n",
    "from pyro.infer import config_enumerate\n",
    "from pyroapi import pyro\n",
    "import pyro.distributions as dist\n",
    "from tqdm import trange\n",
    "\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[('♥', '2'),\n ('♥', '3'),\n ('♥', '4'),\n ('♥', '5'),\n ('♥', '6'),\n ('♥', '7'),\n ('♥', '8'),\n ('♥', '9'),\n ('♥', '10'),\n ('♥', 'J'),\n ('♥', 'Q'),\n ('♥', 'K'),\n ('♥', 'A'),\n ('♠', '2'),\n ('♠', '3'),\n ('♠', '4'),\n ('♠', '5'),\n ('♠', '6'),\n ('♠', '7'),\n ('♠', '8'),\n ('♠', '9'),\n ('♠', '10'),\n ('♠', 'J'),\n ('♠', 'Q'),\n ('♠', 'K'),\n ('♠', 'A'),\n ('♦', '2'),\n ('♦', '3'),\n ('♦', '4'),\n ('♦', '5'),\n ('♦', '6'),\n ('♦', '7'),\n ('♦', '8'),\n ('♦', '9'),\n ('♦', '10'),\n ('♦', 'J'),\n ('♦', 'Q'),\n ('♦', 'K'),\n ('♦', 'A'),\n ('♣', '2'),\n ('♣', '3'),\n ('♣', '4'),\n ('♣', '5'),\n ('♣', '6'),\n ('♣', '7'),\n ('♣', '8'),\n ('♣', '9'),\n ('♣', '10'),\n ('♣', 'J'),\n ('♣', 'Q'),\n ('♣', 'K'),\n ('♣', 'A')]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = [(suite, face) for suite in (\"♥\", \"♠\", \"♦\", \"♣\") for face in\n",
    "         (list(map(str, range(2, 11))) + [\"J\", \"Q\", \"K\", \"A\"])]\n",
    "cards"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def model():\n",
    "    deck = copy(cards)\n",
    "    with pyro.plate(\"draw\"):\n",
    "        card1_index = pyro.sample(\"card1_index\", dist.Categorical(logits=torch.zeros(len(deck))))\n",
    "        card2_index = pyro.sample(\"card2_index\", dist.Categorical(logits=torch.zeros(len(deck) - 1)))\n",
    "        card3_index = pyro.sample(\"card3_index\", dist.Categorical(logits=torch.zeros(len(deck) - 2)))\n",
    "        card4_index = pyro.sample(\"card4_index\", dist.Categorical(logits=torch.zeros(len(deck) - 3)))\n",
    "        card5_index = pyro.sample(\"card5_index\", dist.Categorical(logits=torch.zeros(len(deck) - 4)))\n",
    "\n",
    "    card1 = deck[card1_index]\n",
    "    del deck[card1_index]\n",
    "    card2 = deck[card2_index]\n",
    "    del deck[card2_index]\n",
    "    card3 = deck[card3_index]\n",
    "    del deck[card3_index]\n",
    "    card4 = deck[card4_index]\n",
    "    del deck[card4_index]\n",
    "    card5 = deck[card5_index]\n",
    "    del deck[card5_index]\n",
    "\n",
    "    hand = card1, card2, card3, card4, card5\n",
    "\n",
    "    value = {}\n",
    "    for card in hand:\n",
    "        suite, face = card\n",
    "        if face not in value:\n",
    "            value[face] = set()\n",
    "        value[face].add(suite)\n",
    "\n",
    "    full_house = len(value) == 2 and 2 <= len(list(value.values())[0]) <= 3\n",
    "    assert isinstance(full_house, bool), \"full_house is not a bool\"\n",
    "\n",
    "    if full_house:\n",
    "        print(hand)\n",
    "\n",
    "    with pyro.plate(\"conditional_full_house\"):\n",
    "        p = pyro.sample(\"p\", dist.Uniform(0, 1))\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(p), obs=torch.tensor(full_house, dtype=torch.float))\n",
    "    return hand, full_house"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def guide():\n",
    "    deck = copy(cards)\n",
    "    with pyro.plate(\"draw\"):\n",
    "        card1_index = pyro.sample(\"card1_index\", dist.Categorical(logits=torch.zeros(len(deck))))\n",
    "        card2_index = pyro.sample(\"card2_index\", dist.Categorical(logits=torch.zeros(len(deck) - 1)))\n",
    "        card3_index = pyro.sample(\"card3_index\", dist.Categorical(logits=torch.zeros(len(deck) - 2)))\n",
    "        card4_index = pyro.sample(\"card4_index\", dist.Categorical(logits=torch.zeros(len(deck) - 3)))\n",
    "        card5_index = pyro.sample(\"card5_index\", dist.Categorical(logits=torch.zeros(len(deck) - 4)))\n",
    "\n",
    "    # card1 = deck[card1_index]\n",
    "    # del deck[card1_index]\n",
    "    # card2 = deck[card2_index]\n",
    "    # del deck[card2_index]\n",
    "    # card3 = deck[card3_index]\n",
    "    # del deck[card3_index]\n",
    "    # card4 = deck[card4_index]\n",
    "    # del deck[card4_index]\n",
    "    # card5 = deck[card5_index]\n",
    "    # del deck[card5_index]\n",
    "    #\n",
    "    # hand = card1, card2, card3, card4, card5\n",
    "    #\n",
    "    # value = {}\n",
    "    # for card in hand:\n",
    "    #     suite, face = card\n",
    "    #     if face not in value:\n",
    "    #         value[face] = set()\n",
    "    #     value[face].add(suite)\n",
    "    #\n",
    "    #\n",
    "    # full_house = len(value) == 2 and 2 <= len(list(value.values())[0]) <= 3\n",
    "    # if full_house:\n",
    "    #     print(hand)\n",
    "\n",
    "    with pyro.plate(\"conditional_full_house\"):\n",
    "        p_latent = pyro.param(\"p_latent\", torch.tensor(0.5), constraint=constraints.interval(0, 1))\n",
    "        assert 0 <= p_latent <= 1, f\"p_latent: {p_latent}\"\n",
    "        pyro.sample(\"p\", dist.Delta(p_latent))\n",
    "    #return hand, full_house"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "auto_guide = pyro.infer.autoguide.AutoDelta(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "optim = pyro.optim.ClippedAdam({\"lr\": 0.25, \"lrd\": 0.25})\n",
    "loss = pyro.infer.Trace_ELBO()\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [26]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;241m10_000\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     \u001B[43msvi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/python/sbb/venv/lib/python3.9/site-packages/pyro/infer/svi.py:145\u001B[0m, in \u001B[0;36mSVI.step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;66;03m# get loss and compute gradients\u001B[39;00m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m poutine\u001B[38;5;241m.\u001B[39mtrace(param_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m param_capture:\n\u001B[0;32m--> 145\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_and_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mguide\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\n\u001B[1;32m    148\u001B[0m     site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39munconstrained() \u001B[38;5;28;01mfor\u001B[39;00m site \u001B[38;5;129;01min\u001B[39;00m param_capture\u001B[38;5;241m.\u001B[39mtrace\u001B[38;5;241m.\u001B[39mnodes\u001B[38;5;241m.\u001B[39mvalues()\n\u001B[1;32m    149\u001B[0m )\n\u001B[1;32m    151\u001B[0m \u001B[38;5;66;03m# actually perform gradient steps\u001B[39;00m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001B[39;00m\n",
      "File \u001B[0;32m~/Dev/python/sbb/venv/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:141\u001B[0m, in \u001B[0;36mTrace_ELBO.loss_and_grads\u001B[0;34m(self, model, guide, *args, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# grab a trace from the generator\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_trace, guide_trace \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_traces(model, guide, args, kwargs):\n\u001B[0;32m--> 141\u001B[0m     loss_particle, surrogate_loss_particle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_differentiable_loss_particle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_trace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mguide_trace\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_particle \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_particles\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# collect parameters to train from model and guide\u001B[39;00m\n",
      "File \u001B[0;32m~/Dev/python/sbb/venv/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:106\u001B[0m, in \u001B[0;36mTrace_ELBO._differentiable_loss_particle\u001B[0;34m(self, model_trace, guide_trace)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_identically_zero(score_function_term):\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m log_r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 106\u001B[0m         log_r \u001B[38;5;241m=\u001B[39m \u001B[43m_compute_log_r\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_trace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mguide_trace\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m     site \u001B[38;5;241m=\u001B[39m log_r\u001B[38;5;241m.\u001B[39msum_to(site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcond_indep_stack\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    108\u001B[0m     surrogate_elbo_particle \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    109\u001B[0m         surrogate_elbo_particle \u001B[38;5;241m+\u001B[39m (site \u001B[38;5;241m*\u001B[39m score_function_term)\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m    110\u001B[0m     )\n",
      "File \u001B[0;32m~/Dev/python/sbb/venv/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:28\u001B[0m, in \u001B[0;36m_compute_log_r\u001B[0;34m(model_trace, guide_trace)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_site[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_observed\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m     27\u001B[0m             log_r_term \u001B[38;5;241m=\u001B[39m log_r_term \u001B[38;5;241m-\u001B[39m guide_trace\u001B[38;5;241m.\u001B[39mnodes[name][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog_prob\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m---> 28\u001B[0m         \u001B[43mlog_r\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstacks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_r_term\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m log_r\n",
      "File \u001B[0;32m~/Dev/python/sbb/venv/lib/python3.9/site-packages/pyro/infer/util.py:144\u001B[0m, in \u001B[0;36mMultiFrameTensor.add\u001B[0;34m(self, *items)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cond_indep_stack, value \u001B[38;5;129;01min\u001B[39;00m items:\n\u001B[1;32m    143\u001B[0m     frames \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfrozenset\u001B[39m(f \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m cond_indep_stack \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mvectorized)\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(f\u001B[38;5;241m.\u001B[39mdim \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241m-\u001B[39mvalue\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mdim \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m frames)\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frames \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m    146\u001B[0m         \u001B[38;5;28mself\u001B[39m[frames] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m[frames] \u001B[38;5;241m+\u001B[39m value\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for _ in trange(10_000):\n",
    "    svi.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pyro.param(\"p_latent\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "kernel = pyro.infer.NUTS(model)\n",
    "mcmc = pyro.infer.MCMC(kernel, num_samples=1000, warmup_steps=100, num_chains=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mcmc.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "marginals = pyro.infer.EmpericalMarginal(mcmc.get_samples())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}