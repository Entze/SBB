{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import string\n",
    "from functools import reduce\n",
    "from typing import Union\n",
    "\n",
    "import funsor\n",
    "import torch\n",
    "from pyro import set_rng_seed as pyro_set_rng_seed\n",
    "from torch import Tensor\n",
    "\n",
    "funsor.set_backend(\"torch\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "pyro_set_rng_seed(0)\n",
    "\n",
    "from pyroapi import pyro\n",
    "\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]) torch.Size([26])\n"
     ]
    }
   ],
   "source": [
    "all_lower_alphas = torch.tensor([ord(letter) for letter in string.ascii_lowercase])\n",
    "print(all_lower_alphas, all_lower_alphas.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "all_digits = torch.tensor([ord(d) for d in string.digits])\n",
    "print(all_digits, all_digits.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def enumerate_sequences(*args, shift: int = 8) -> Tensor: # IDEA: make shift broadcastable (i.e. shift according to space requirement)\n",
    "    if not args:\n",
    "        raise ValueError(\"At least one tensor required\")\n",
    "    worklist = [arg for arg in args]\n",
    "    with torch.no_grad():\n",
    "        t = worklist.pop()\n",
    "        if isinstance(t, tuple):\n",
    "            replicate, tensor = t\n",
    "            for i in range(replicate - 1):\n",
    "                worklist.append(torch.clone(tensor))\n",
    "            t = tensor\n",
    "        result = torch.clone(t)\n",
    "        while worklist:\n",
    "            t = worklist.pop()\n",
    "            if isinstance(t, tuple):\n",
    "                replicate, tensor = t\n",
    "                for i in range(replicate):\n",
    "                    worklist.append(torch.clone(tensor))\n",
    "                continue\n",
    "            for _d in result.size():\n",
    "                t = torch.unsqueeze(t, -1)\n",
    "            result = (result << shift) + t\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def count_sequences(*args) -> int:\n",
    "    if not args:\n",
    "        return 0\n",
    "    result = 1\n",
    "    index = 0\n",
    "    while index < len(args):\n",
    "        t = args[index]\n",
    "        if isinstance(t, tuple):\n",
    "            r, tensor = t\n",
    "            t = tensor\n",
    "        else:\n",
    "            r = 1\n",
    "        result *= count_elems(t) ** r\n",
    "        index += 1\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def count_elems(t: Union[Tensor, torch.Size]) -> int:\n",
    "    if isinstance(t, Tensor):\n",
    "        t = t.size()\n",
    "    return reduce(operator.mul, t, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 12.7 s, total: 21.4 s\n",
      "Wall time: 2.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "4569760000"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "p = enumerate_sequences((4, all_lower_alphas), (4, all_digits))\n",
    "count_elems(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 55 µs, total: 95 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": "4569760000"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "count_sequences((4, all_lower_alphas), (4, all_digits))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 687 ms, total: 1.9 s\n",
      "Wall time: 641 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "2028000"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "p = enumerate_sequences(torch.tensor(ord('T')), torch.tensor([ord('A'), ord('H'), ord('M')]), (2, all_lower_alphas), (3, all_digits), torch.tensor(9))\n",
    "count_elems(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 µs, sys: 38 µs, total: 68 µs\n",
      "Wall time: 52.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": "2028000"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "count_sequences(torch.tensor(ord('T')), torch.tensor([ord('A'), ord('H'), ord('M')]), (2, all_lower_alphas), (3, all_digits), torch.tensor(9))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}