{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from inspect import isclass\n",
    "\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import config_enumerate, JitTraceEnum_ELBO, SVI, Trace_ELBO\n",
    "from pyroapi import pyro\n",
    "from torch import nn\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "['bad1',\n 'bad2',\n 'bad3',\n 'bad4',\n 'bad5',\n 'good1',\n 'good2',\n 'good3',\n 'good4',\n 'good5']"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"bad{}\".format(i + 1) for i in range(5)] + [\"good{}\".format(i + 1) for i in range(5)]\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[['good5', 'bad4', 'bad4'],\n ['good4', 'bad1', 'good5', 'bad1', 'good2', 'bad4'],\n ['good3', 'good1', 'bad2', 'good3', 'bad2', 'bad5'],\n ['good4', 'bad3', 'bad5', 'bad2', 'bad4', 'good4'],\n ['bad3', 'good1', 'good5', 'bad5', 'good4', 'good5'],\n ['good2', 'good4', 'good5', 'bad5', 'bad2', 'bad3'],\n ['bad4', 'bad1', 'bad5'],\n ['bad5', 'good3', 'bad2', 'bad2', 'good1', 'good5'],\n ['good5', 'bad1', 'bad1'],\n ['bad1', 'good5', 'bad1', 'good1', 'bad5', 'bad4']]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for i in range(10):\n",
    "    length = torch.distributions.LogNormal(1., .5).sample().int().item() * 3\n",
    "    sentences.append(random.choices(words, k=length))\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def label(sentence):\n",
    "    bads = 0\n",
    "    for word in sentence:\n",
    "        if word.startswith('b'):\n",
    "            bads += 1\n",
    "\n",
    "    return int(bads > (len(sentence) - bads))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "([['good5', 'bad4', 'bad4'],\n  ['good4', 'bad1', 'good5', 'bad1', 'good2', 'bad4'],\n  ['good3', 'good1', 'bad2', 'good3', 'bad2', 'bad5'],\n  ['good4', 'bad3', 'bad5', 'bad2', 'bad4', 'good4'],\n  ['bad3', 'good1', 'good5', 'bad5', 'good4', 'good5'],\n  ['good2', 'good4', 'good5', 'bad5', 'bad2', 'bad3'],\n  ['bad4', 'bad1', 'bad5'],\n  ['bad5', 'good3', 'bad2', 'bad2', 'good1', 'good5'],\n  ['good5', 'bad1', 'bad1'],\n  ['bad1', 'good5', 'bad1', 'good1', 'bad5', 'bad4']],\n [1, 0, 0, 1, 0, 0, 1, 0, 1, 1])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label(sentence) for sentence in sentences]\n",
    "sentences, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "({'good5': 1,\n  'bad4': 2,\n  'good4': 3,\n  'bad1': 4,\n  'good2': 5,\n  'good3': 6,\n  'good1': 7,\n  'bad2': 8,\n  'bad5': 9,\n  'bad3': 10},\n [[1, 2, 2, 0, 0, 0],\n  [3, 4, 1, 4, 5, 2],\n  [6, 7, 8, 6, 8, 9],\n  [3, 10, 9, 8, 2, 3],\n  [10, 7, 1, 9, 3, 1],\n  [5, 3, 1, 9, 8, 10],\n  [2, 4, 9, 0, 0, 0],\n  [9, 6, 8, 8, 7, 1],\n  [1, 4, 4, 0, 0, 0],\n  [4, 1, 4, 7, 9, 2]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = dict()\n",
    "vec_len = max(len(sentence) for sentence in sentences)\n",
    "counter = 1\n",
    "sentences_vec = []\n",
    "for sentence in sentences:\n",
    "    vec = [0 for _ in range(vec_len)]\n",
    "    for i, word in enumerate(sentence):\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = counter\n",
    "            counter += 1\n",
    "        vec[i] = vocabulary[word]\n",
    "    sentences_vec.append(vec)\n",
    "\n",
    "vocabulary, sentences_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class Exp(nn.Module):\n",
    "    \"\"\"\n",
    "    a custom module for exponentiation of tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, val):\n",
    "        return torch.exp(val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class ConcatModule(nn.Module):\n",
    "    \"\"\"\n",
    "    a custom module for concatenation of tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, allow_broadcast=False):\n",
    "        self.allow_broadcast = allow_broadcast\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, *input_args):\n",
    "        # we have a single object\n",
    "        if len(input_args) == 1:\n",
    "            # regardless of type,\n",
    "            # we don't care about single objects\n",
    "            # we just index into the object\n",
    "            input_args = input_args[0]\n",
    "\n",
    "        # don't concat things that are just single objects\n",
    "        if torch.is_tensor(input_args):\n",
    "            return input_args\n",
    "        else:\n",
    "            if self.allow_broadcast:\n",
    "                shape = broadcast_shape(*[s.shape[:-1] for s in input_args]) + (-1,)\n",
    "                input_args = [s.expand(shape) for s in input_args]\n",
    "            return torch.cat(input_args, dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class ListOutModule(nn.ModuleList):\n",
    "    \"\"\"\n",
    "    a custom module for outputting a list of tensors from a list of nn modules\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, modules):\n",
    "        super().__init__(modules)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # loop over modules in self, apply same args\n",
    "        return [mm.forward(*args, **kwargs) for mm in self]\n",
    "\n",
    "\n",
    "def call_nn_op(op):\n",
    "    \"\"\"\n",
    "    a helper function that adds appropriate parameters when calling\n",
    "    an nn module representing an operation like Softmax\n",
    "    :param op: the nn.Module operation to instantiate\n",
    "    :return: instantiation of the op module with appropriate parameters\n",
    "    \"\"\"\n",
    "    if op in [nn.Softmax, nn.LogSoftmax]:\n",
    "        return op(dim=1)\n",
    "    else:\n",
    "        return op()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            mlp_sizes,\n",
    "            activation=nn.ReLU,\n",
    "            output_activation=None,\n",
    "            post_layer_fct=lambda layer_ix, total_layers, layer: None,\n",
    "            post_act_fct=lambda layer_ix, total_layers, layer: None,\n",
    "            allow_broadcast=False,\n",
    "            use_cuda=False,\n",
    "    ):\n",
    "        # init the module object\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(mlp_sizes) >= 2, \"Must have input and output layer sizes defined\"\n",
    "\n",
    "        # get our inputs, outputs, and hidden\n",
    "        input_size, hidden_sizes, output_size = (\n",
    "            mlp_sizes[0],\n",
    "            mlp_sizes[1:-1],\n",
    "            mlp_sizes[-1],\n",
    "        )\n",
    "\n",
    "        # assume int or list\n",
    "        assert isinstance(\n",
    "            input_size, (int, list, tuple)\n",
    "        ), \"input_size must be int, list, tuple\"\n",
    "\n",
    "        # everything in MLP will be concatted if it's multiple arguments\n",
    "        last_layer_size = input_size if type(input_size) == int else sum(input_size)\n",
    "\n",
    "        # everything sent in will be concatted together by default\n",
    "        all_modules = [ConcatModule(allow_broadcast)]\n",
    "\n",
    "        # loop over l\n",
    "        for layer_ix, layer_size in enumerate(hidden_sizes):\n",
    "            assert type(layer_size) == int, \"Hidden layer sizes must be ints\"\n",
    "\n",
    "            # get our nn layer module (in this case nn.Linear by default)\n",
    "            cur_linear_layer = nn.Linear(last_layer_size, layer_size)\n",
    "\n",
    "            # for numerical stability -- initialize the layer properly\n",
    "            cur_linear_layer.weight.data.normal_(0, 0.001)\n",
    "            cur_linear_layer.bias.data.normal_(0, 0.001)\n",
    "\n",
    "            # use GPUs to share data during training (if available)\n",
    "            if use_cuda:\n",
    "                cur_linear_layer = nn.DataParallel(cur_linear_layer)\n",
    "\n",
    "            # add our linear layer\n",
    "            all_modules.append(cur_linear_layer)\n",
    "\n",
    "            # handle post_linear\n",
    "            post_linear = post_layer_fct(\n",
    "                layer_ix + 1, len(hidden_sizes), all_modules[-1]\n",
    "            )\n",
    "\n",
    "            # if we send something back, add it to sequential\n",
    "            # here we could return a batch norm for example\n",
    "            if post_linear is not None:\n",
    "                all_modules.append(post_linear)\n",
    "\n",
    "            # handle activation (assumed no params -- deal with that later)\n",
    "            all_modules.append(activation())\n",
    "\n",
    "            # now handle after activation\n",
    "            post_activation = post_act_fct(\n",
    "                layer_ix + 1, len(hidden_sizes), all_modules[-1]\n",
    "            )\n",
    "\n",
    "            # handle post_activation if not null\n",
    "            # could add batch norm for example\n",
    "            if post_activation is not None:\n",
    "                all_modules.append(post_activation)\n",
    "\n",
    "            # save the layer size we just created\n",
    "            last_layer_size = layer_size\n",
    "\n",
    "        # now we have all of our hidden layers\n",
    "        # we handle outputs\n",
    "        assert isinstance(\n",
    "            output_size, (int, list, tuple)\n",
    "        ), \"output_size must be int, list, tuple\"\n",
    "\n",
    "        if type(output_size) == int:\n",
    "            all_modules.append(nn.Linear(last_layer_size, output_size))\n",
    "            if output_activation is not None:\n",
    "                all_modules.append(\n",
    "                    call_nn_op(output_activation)\n",
    "                    if isclass(output_activation)\n",
    "                    else output_activation\n",
    "                )\n",
    "        else:\n",
    "\n",
    "            # we're going to have a bunch of separate layers we can spit out (a tuple of outputs)\n",
    "            out_layers = []\n",
    "\n",
    "            # multiple outputs? handle separately\n",
    "            for out_ix, out_size in enumerate(output_size):\n",
    "\n",
    "                # for a single output object, we create a linear layer and some weights\n",
    "                split_layer = []\n",
    "\n",
    "                # we have an activation function\n",
    "                split_layer.append(nn.Linear(last_layer_size, out_size))\n",
    "\n",
    "                # then we get our output activation (either we repeat all or we index into a same sized array)\n",
    "                act_out_fct = (\n",
    "                    output_activation\n",
    "                    if not isinstance(output_activation, (list, tuple))\n",
    "                    else output_activation[out_ix]\n",
    "                )\n",
    "\n",
    "                if act_out_fct:\n",
    "                    # we check if it's a class. if so, instantiate the object\n",
    "                    # otherwise, use the object directly (e.g. pre-instaniated)\n",
    "                    split_layer.append(\n",
    "                        call_nn_op(act_out_fct) if isclass(act_out_fct) else act_out_fct\n",
    "                    )\n",
    "\n",
    "                # our outputs is just a sequential of the two\n",
    "                out_layers.append(nn.Sequential(*split_layer))\n",
    "\n",
    "            all_modules.append(ListOutModule(out_layers))\n",
    "\n",
    "        # now we have all of our modules, we're ready to build our sequential!\n",
    "        # process mlps in order, pretty standard here\n",
    "        self.sequential_mlp = nn.Sequential(*all_modules)\n",
    "\n",
    "    # pass through our sequential for the output!\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.sequential_mlp.forward(*args, **kwargs)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class SSVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    This class encapsulates the parameters (neural networks) and models & guides needed to train a\n",
    "    semi-supervised variational auto-encoder on the MNIST image dataset\n",
    "    :param output_size: size of the tensor representing the class label (10 for MNIST since\n",
    "                        we represent the class labels as a one-hot vector with 10 components)\n",
    "    :param input_size: size of the tensor representing the image (28*28 = 784 for our MNIST dataset\n",
    "                       since we flatten the images and scale the pixels to be in [0,1])\n",
    "    :param z_dim: size of the tensor representing the latent random variable z\n",
    "                  (handwriting style for our MNIST dataset)\n",
    "    :param hidden_layers: a tuple (or list) of MLP layers to be used in the neural networks\n",
    "                          representing the parameters of the distributions in our model\n",
    "    :param use_cuda: use GPUs for faster training\n",
    "    :param aux_loss_multiplier: the multiplier to use with the auxiliary loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_size=2,\n",
    "            input_size=vec_len,\n",
    "            z_dim=vec_len*3,\n",
    "            hidden_layers=(vec_len*3,),\n",
    "            config_enum=None,\n",
    "            use_cuda=False,\n",
    "            aux_loss_multiplier=None,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize the class with all arguments provided to the constructor\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.allow_broadcast = config_enum == \"parallel\"\n",
    "        self.use_cuda = use_cuda\n",
    "        self.aux_loss_multiplier = aux_loss_multiplier\n",
    "\n",
    "        # define and instantiate the neural networks representing\n",
    "        # the paramters of various distributions in the model\n",
    "        self.setup_networks()\n",
    "\n",
    "    def setup_networks(self):\n",
    "\n",
    "        z_dim = self.z_dim\n",
    "        if isinstance(self.hidden_layers, list):\n",
    "            hidden_sizes = self.hidden_layers\n",
    "        else:\n",
    "            hidden_sizes = [size for size in self.hidden_layers]\n",
    "\n",
    "        # define the neural networks used later in the model and the guide.\n",
    "        # these networks are MLPs (multi-layered perceptrons or simple feed-forward networks)\n",
    "        # where the provided activation parameter is used on every linear layer except\n",
    "        # for the output layer where we use the provided output_activation parameter\n",
    "        self.encoder_y = MLP(\n",
    "            [self.input_size] + hidden_sizes + [self.output_size],\n",
    "            activation=nn.Softplus,\n",
    "            output_activation=nn.Softmax,\n",
    "            allow_broadcast=self.allow_broadcast,\n",
    "            use_cuda=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        # a split in the final layer's size is used for multiple outputs\n",
    "        # and potentially applying separate activation functions on them\n",
    "        # e.g. in this network the final output is of size [z_dim,z_dim]\n",
    "        # to produce loc and scale, and apply different activations [None,Exp] on them\n",
    "        self.encoder_z = MLP(\n",
    "            [self.input_size + self.output_size] + hidden_sizes + [[z_dim, z_dim]],\n",
    "            activation=nn.Softplus,\n",
    "            output_activation=[None, Exp],\n",
    "            allow_broadcast=self.allow_broadcast,\n",
    "            use_cuda=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        self.decoder = MLP(\n",
    "            [z_dim + self.output_size] + hidden_sizes + [self.input_size],\n",
    "            activation=nn.Softplus,\n",
    "            output_activation=nn.Sigmoid,\n",
    "            allow_broadcast=self.allow_broadcast,\n",
    "            use_cuda=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        # using GPUs for faster training of the networks\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def model(self, xs, ys=None):\n",
    "        \"\"\"\n",
    "        The model corresponds to the following generative process:\n",
    "        p(z) = normal(0,I)              # handwriting style (latent)\n",
    "        p(y|x) = categorical(I/10.)     # which digit (semi-supervised)\n",
    "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
    "        loc is given by a neural network  `decoder`\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :param ys: (optional) a batch of the class labels i.e.\n",
    "                   the digit corresponding to the image(s)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"ss_vae\", self)\n",
    "\n",
    "        batch_size = xs.size(0)\n",
    "        options = dict(dtype=xs.dtype, device=xs.device)\n",
    "        with pyro.plate(\"data\"):\n",
    "            # sample the handwriting style from the constant prior distribution\n",
    "            prior_logits = torch.zeros(batch_size, self.z_dim, **options)\n",
    "            zs = pyro.sample(\"z\", dist.RelaxedOneHotCategoricalStraightThrough(logits=prior_logits).to_event(1))\n",
    "\n",
    "            # if the label y (which digit to write) is supervised, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "            ys = pyro.sample(\"y\", dist.RelaxedBernoulliStraightThrough(torch.tensor(0.5)), obs=ys)\n",
    "\n",
    "            # Finally, score the image (x) using the handwriting style (z) and\n",
    "            # the class label y (which digit to write) against the\n",
    "            # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
    "            # where `decoder` is a neural network. We disable validation\n",
    "            # since the decoder output is a relaxed Bernoulli value.\n",
    "            logits = self.decoder.forward([zs, ys])\n",
    "            pyro.sample(\n",
    "                \"x\", dist.Categorical(logits=logits, validate_args=False).to_event(1), obs=xs\n",
    "            )\n",
    "            # return the loc so we can visualize it later\n",
    "            return logits\n",
    "\n",
    "    def guide(self, xs, ys=None):\n",
    "        \"\"\"\n",
    "        The guide corresponds to the following:\n",
    "        q(y|x) = categorical(alpha(x))              # infer digit from an image\n",
    "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer handwriting style from an image and the digit\n",
    "        loc, scale are given by a neural network `encoder_z`\n",
    "        alpha is given by a neural network `encoder_y`\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :param ys: (optional) a batch of the class labels i.e.\n",
    "                   the digit corresponding to the image(s)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "            # if the class label (the digit) is not supervised, sample\n",
    "            # (and score) the digit with the variational distribution\n",
    "            # q(y|x) = categorical(alpha(x))\n",
    "            if ys is None:\n",
    "                p = self.encoder_y.forward(xs)\n",
    "                ys = pyro.sample(\"y\", dist.RelaxedBernoulliStraightThrough(p))\n",
    "\n",
    "            # sample (and score) the latent handwriting-style with the variational\n",
    "            # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "            logits = self.encoder_z.forward([xs, ys])\n",
    "            pyro.sample(\"z\", dist.RelaxedOneHotCategoricalStraightThrough(logits).to_event(1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# batch_size: number of images (and labels) to be considered in a batch\n",
    "ss_vae = SSVAE(\n",
    "    use_cuda=True,\n",
    "    config_enum=\"parallel\",\n",
    ")\n",
    "\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.025, \"betas\": (0.95, 0.999)}\n",
    "optimizer = pyro.optim.Adam(adam_params)\n",
    "\n",
    "# set up the loss(es) for inference. wrapping the guide in config_enumerate builds the loss as a sum\n",
    "# by enumerating each class label for the sampled discrete categorical distribution in the model\n",
    "guide = config_enumerate(ss_vae.guide, \"parallel\", expand=True)\n",
    "Elbo = Trace_ELBO\n",
    "elbo = Elbo(max_plate_nesting=1, strict_enumeration_warning=False)\n",
    "loss_basic = SVI(ss_vae.model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# build a list of all losses considered\n",
    "losses = [loss_basic]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def run_inference_for_epoch(xs, ys, losses):\n",
    "    \"\"\"\n",
    "    runs the inference algorithm for an epoch\n",
    "    returns the values of all losses separately on supervised and unsupervised parts\n",
    "    \"\"\"\n",
    "    num_losses = len(losses)\n",
    "    epoch_losses = []\n",
    "\n",
    "\n",
    "    # count the number of supervised batches seen in this epoch\n",
    "\n",
    "    # run the inference for each loss with supervised or un-supervised\n",
    "    # data as arguments\n",
    "    for loss_id in range(num_losses):\n",
    "        new_loss = losses[loss_id].step(xs, ys)\n",
    "        epoch_losses[loss_id] += new_loss\n",
    "\n",
    "    # return the values of all losses\n",
    "    return epoch_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5111df4fd9c344ee85e37421c2b45ce8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x16 and 8x18)\nTrace Shapes:\n Param Sites:\nSample Sites:",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m                 \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/poutine/messenger.py\u001B[0m in \u001B[0;36m_context_wrap\u001B[0;34m(context, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7141/1323291143.py\u001B[0m in \u001B[0;36mguide\u001B[0;34m(self, xs, ys)\u001B[0m\n\u001B[1;32m    147\u001B[0m             \u001B[0;31m# distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 148\u001B[0;31m             \u001B[0mlogits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder_z\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    149\u001B[0m             \u001B[0mpyro\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"z\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRelaxedOneHotCategoricalStraightThrough\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7141/3030426085.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msequential_mlp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    165\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_ids\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 166\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    167\u001B[0m             \u001B[0mreplicas\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplicate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_ids\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1847\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1848\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (10x16 and 8x18)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7141/3463689737.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mepoch_losses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_inference_for_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentences_vec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_7141/1202504549.py\u001B[0m in \u001B[0;36mrun_inference_for_epoch\u001B[0;34m(xs, ys, losses)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;31m# data as arguments\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mloss_id\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_losses\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mnew_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloss_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0mepoch_losses\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloss_id\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mnew_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/infer/svi.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m         \u001B[0;31m# get loss and compute gradients\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mpoutine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mparam_capture\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_and_grads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mguide\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         params = set(\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/infer/trace_elbo.py\u001B[0m in \u001B[0;36mloss_and_grads\u001B[0;34m(self, model, guide, *args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m         \u001B[0;31m# grab a trace from the generator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mmodel_trace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mguide_trace\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_traces\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mguide\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m             loss_particle, surrogate_loss_particle = self._differentiable_loss_particle(\n\u001B[1;32m    142\u001B[0m                 \u001B[0mmodel_trace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mguide_trace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/infer/elbo.py\u001B[0m in \u001B[0;36m_get_traces\u001B[0;34m(self, model, guide, args, kwargs)\u001B[0m\n\u001B[1;32m    180\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_particles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 182\u001B[0;31m                 \u001B[0;32myield\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_trace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mguide\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/infer/trace_elbo.py\u001B[0m in \u001B[0;36m_get_trace\u001B[0;34m(self, model, guide, args, kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0magainst\u001B[0m \u001B[0mit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \"\"\"\n\u001B[0;32m---> 57\u001B[0;31m         model_trace, guide_trace = get_importance_trace(\n\u001B[0m\u001B[1;32m     58\u001B[0m             \u001B[0;34m\"flat\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_plate_nesting\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mguide\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m         )\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/infer/enum.py\u001B[0m in \u001B[0;36mget_importance_trace\u001B[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mmodel_trace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mguide_trace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munwrapped_guide\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_traces\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         guide_trace = poutine.trace(guide, graph_type=graph_type).get_trace(\n\u001B[0m\u001B[1;32m     61\u001B[0m             \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         )\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py\u001B[0m in \u001B[0;36mget_trace\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    196\u001B[0m         \u001B[0mCalls\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mpoutine\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0mits\u001B[0m \u001B[0mtrace\u001B[0m \u001B[0minstead\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0ms\u001B[0m \u001B[0;32mreturn\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m         \"\"\"\n\u001B[0;32m--> 198\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    199\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmsngr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_trace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m                 \u001B[0mexc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexc_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mu\"{}\\n{}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshapes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m                 \u001B[0mexc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraceback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m             self.msngr.trace.add_node(\n\u001B[1;32m    182\u001B[0m                 \u001B[0;34m\"_RETURN\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"_RETURN\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"return\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mret\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    172\u001B[0m             )\n\u001B[1;32m    173\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m                 \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m                 \u001B[0mexc_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexc_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraceback\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.miniconda3/envs/SBB/lib/python3.9/site-packages/pyro/poutine/messenger.py\u001B[0m in \u001B[0;36m_context_wrap\u001B[0;34m(context, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_context_wrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7141/1323291143.py\u001B[0m in \u001B[0;36mguide\u001B[0;34m(self, xs, ys)\u001B[0m\n\u001B[1;32m    146\u001B[0m             \u001B[0;31m# sample (and score) the latent handwriting-style with the variational\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m             \u001B[0;31m# distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 148\u001B[0;31m             \u001B[0mlogits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder_z\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    149\u001B[0m             \u001B[0mpyro\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"z\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRelaxedOneHotCategoricalStraightThrough\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7141/3030426085.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    130\u001B[0m     \u001B[0;31m# pass through our sequential for the output!\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msequential_mlp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_ids\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 166\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    167\u001B[0m             \u001B[0mreplicas\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplicate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_ids\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparallel_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreplicas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1846\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1847\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1848\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1850\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (10x16 and 8x18)\nTrace Shapes:\n Param Sites:\nSample Sites:"
     ]
    }
   ],
   "source": [
    "for _ in trange(5):\n",
    "    epoch_losses = run_inference_for_epoch(torch.tensor(sentences_vec), torch.tensor(labels), losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}